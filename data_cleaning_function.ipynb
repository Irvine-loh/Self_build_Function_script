{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "data_cleaning_function.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c131bf9"
      },
      "source": [
        "# Data Cleaning Function\n",
        "#### def data_cleaning (dataframe,replace_missing_value)\n",
        "#### return dataframe\n",
        "##### Written by : Loh Khai Shyang\n",
        "##### Scripted Date : 22 Nov 2021"
      ],
      "id": "6c131bf9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9511db9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def data_cleaning(df,replace_missing_value = value to be filled into missing rows):\n",
        "    ### 1. search_remove_individual_value_features\n",
        "    ### 2. replace_missing_data\n",
        "    ### 3. blank_space_repalcement\n",
        "    \n",
        "    ### return dataframe thru data cleaning process\n",
        "    \n",
        "    ### Hyper- Parameter\n",
        "        # 1. df = Dataframe to be clean\n",
        "        # 2. replace_missing_value = value to be filled into missing rows\n",
        "\n",
        "        \n",
        "    def basic_data_info(df):\n",
        "        # check dataset overall information\n",
        "        print('\\nData Cleaning Report - Basic Data Informations\\n')\n",
        "        print(df.info())\n",
        "\n",
        "        print('\\nData Cleaning Report - Summary of total \"NAN\" rows\\n')\n",
        "        # identify amount of  \"NAN\" row\n",
        "        print(df.isna().sum())\n",
        "\n",
        "\n",
        "\n",
        "    def search_remove_individual_value_features(df):\n",
        "        # remove features if :\n",
        "            # X[i].unique() == 1\n",
        "            # X[i].unique() == 2 & np.nan isin( X[i].unique() )\n",
        "            # X[i].unique() == 2 & ' ' isin( X[i].unique())  ### ' ' == empty space\n",
        "        \n",
        "        column_name = df.columns\n",
        "        remove_single_value_features_list=[]\n",
        "        \n",
        "        for name in column_name:\n",
        "\n",
        "\n",
        "            if len(df[name].unique())==1: # X[i].unique() == 1\n",
        "                remove_single_value_features_list=np.append(name,remove_single_value_features_list)\n",
        "            \n",
        "            elif len(df[name].unique())==2 and np.nan in(df[name].unique()): # X[i].unique() == 2 & np.nan isin( X[i].unique() )\n",
        "                remove_single_value_features_list=np.append(name,remove_single_value_features_list)\n",
        "                \n",
        "            elif len(df[name].unique())==2 and ' ' in(df[name].unique()): # X[i].unique() == 2 & ' ' isin( X[i].unique())  ### ' ' == empty space\n",
        "                remove_single_value_features_list=np.append(name,remove_single_value_features_list)\n",
        "\n",
        "\n",
        "        if len(remove_single_value_features_list)>=1:\n",
        "            print('\\nData Cleaning Report - Individual Value feature removed : ',remove_single_value_features_list)\n",
        "            df.drop(remove_single_value_features_list,axis=1,inplace=True)\n",
        "        else:\n",
        "            print(\"\\nData Cleaning Report - No Individual Value feature Found !!\\n\")\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def replace_missing_data(df,replace_missing_value):\n",
        "        # user can define what value to fill in to missing data\n",
        "        # \"nan\" and \"blank space\" consider missing data\n",
        "\n",
        "        column_list= df.columns\n",
        "        missing_EmptySpace_data_dict_list={} # Store \"Empty Space\" row in dictionary by column name\n",
        "        missing_NAN_data_dict_list={} # # Store \"nan\" row in dictionary by column name\n",
        "\n",
        "        for column in column_list:\n",
        "            if len(df.loc[df[column]==' '])!= 0 :\n",
        "                missing_EmptySpace_data_dict_list[column]=df.loc[df[column]==' '].index # index \n",
        "            elif len(df.loc[df[column]==np.nan])!=0:\n",
        "                missing_NAN_data_dict_list[column]=df.loc[df[column]==np.nan].index\n",
        "\n",
        "        ## replace missing data function\n",
        "        if len(missing_EmptySpace_data_dict_list)!=0 : # check empty_space_column dictionary is empty or not\n",
        "\n",
        "            print('\\nData Cleaning Report - Have Missing \"Empty Space\" Data :\\n',missing_EmptySpace_data_dict_list)\n",
        "\n",
        "            for key in missing_EmptySpace_data_dict_list.keys():\n",
        "                df.loc[missing_EmptySpace_data_dict_list[key],key]=replace_missing_value # df.loc[idx list, column name] = 0\n",
        "\n",
        "        elif len(missing_NAN_data_dict_list)!=0 : # check empty_space_column dictionary is empty or not:\n",
        "\n",
        "            print('\\nData Cleaning Report - Have Missing \"NaN\" Data :\\n',missing_NAN_data_dict_list)\n",
        "\n",
        "            for key in missing_NAN_data_dict_list.keys():\n",
        "                df.loc[missing_NAN_data_dict_list[key],key]=replace_missing_value # df.loc[idx list, column name] = 0\n",
        "\n",
        "        else:\n",
        "            print('\\nData Cleaning Report - No Missing Data or \"Nan\" row Found !!\\n')\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "    def blank_space_repalcement(df):\n",
        "        # Dataframe Column Name Blank Space Replacement\n",
        "        df.columns=df.columns.str.replace(' ','_')\n",
        "        df.replace(' ','_',regex=True,inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    basic_data_info(df)\n",
        "    df=search_remove_individual_value_features(df)\n",
        "    df=replace_missing_data(df,replace_missing_value)\n",
        "    df=blank_space_repalcement(df)\n",
        "\n",
        "    return df"
      ],
      "id": "a9511db9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1297c889"
      },
      "source": [
        "def imbalance_data_check(df,label_name):\n",
        "    # SuitabLe for categorical class label [both ordinal or nominal data]\n",
        "    \n",
        "    \n",
        "    \n",
        "    ## Frequency Table of Label data ##\n",
        "#     print('\\n Imbalance Data Check - Label vs Features Table \\n',df.groupby([label_name]).count(),'\\n')\n",
        "    \n",
        "    freq_table=df.groupby([label_name]).size().reset_index(name='Count')\n",
        "\n",
        "    print('\\n Imbalance Data Check - Frequency Table of Label Data :\\n',freq_table,'\\n')\n",
        "    \n",
        "    \n",
        "    \n",
        "    ## % of label's class distribution data Summary ##\n",
        "    summary={}\n",
        "\n",
        "    unique_class=freq_table[label_name].unique()\n",
        "    total_count=freq_table['Count'].sum()\n",
        "    \n",
        "    for i in range(len(unique_class)):\n",
        "        summary[unique_class[i]]= [(freq_table['Count'][i]/total_count)*100] \n",
        "        \n",
        "    summary_df=pd.DataFrame(data=summary)\n",
        "    \n",
        "    print(f'Imbalance Data Check - Label Data Distribution % :\\n{summary_df}')\n",
        "\n",
        "          \n",
        "          \n",
        "          \n",
        "    ##  Plot Figure of Label class data distribution ##\n",
        "    print(f'\\nImbalance Data Check - Data Distribution % Summary Plot :\\n') # Imbalance data check summary\n",
        "    \n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "    ax=sns.barplot(x=label_name,y=\"Count\", data=freq_table)\n",
        "    \n",
        "    for i in unique_class:\n",
        "        num=round(summary[i][0],2)\n",
        "#         value=str(num)+'%'\n",
        "        ax.text(i,num,round(num,2), color='black', ha=\"center\")\n",
        "\n",
        "    return"
      ],
      "id": "1297c889",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "931d10cf"
      },
      "source": [
        "def numeric_histogram_plot_for_classification_model(df,label_feature,save_photo):\n",
        "    # label_feature = input label feature name\n",
        "    # df = input dataframe to be process\n",
        "    # save_photo = True ( auto saved), Default==\"False\"\n",
        "    \n",
        "    # sns.displot(daframe,x=\"column name to plot on x-axis\",hue=label_feature, element=\"step\")\n",
        "    # subplot link : https://datavizpyr.com/seaborn-join-two-plots-with-shared-y-axis/\n",
        "    \n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    \n",
        "    plot_columns=list(df.select_dtypes(include=['int32','int64','float64','float32']).columns)\n",
        "    \n",
        "    if label_feature in(plot_columns):\n",
        "        plot_columns.remove(label_feature)\n",
        "    \n",
        "    for i,column in zip( range(len(plot_columns)), plot_columns ):\n",
        "        plt.figure(i)\n",
        "        sns_plot=sns.displot(data=df,x=column,hue=label_feature, element=\"step\",kde=True)\n",
        "        plt.title(column+\" - Displot Plot\")\n",
        "        \n",
        "#         sns.histplot(df, x=column,hue=label_feature, element=\"step\", kde=True)\n",
        "#         plt.title(column+\" - Histogram Plot\")\n",
        "#         plt.show()\n",
        "        \n",
        "        if save_photo==True:\n",
        "            sns_plot.savefig(column+\".png\")     # auto Saved figure file \n",
        "            \n",
        "    return\n"
      ],
      "id": "931d10cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c96c04af"
      },
      "source": [
        "def numeric_histplot(df,label):\n",
        "    # label must vbe a list of feature to plot\n",
        "    \n",
        "    for i, feature in label:\n",
        "        plt.figure(i)\n",
        "        sns_plot=sns.displot(data=df,x=feature, element=\"step\",kde=True)\n",
        "        plt.title(feature+\" - Displot Plot\")\n",
        "        \n",
        "    return\n",
        "\n",
        "def numeric_compare_histplot(df_1,df_2,compare_label,compare_name):\n",
        "    # Plot two dataframe histplot for in one graph df_1 and df_2 for comparison plot\n",
        "    # compare_label must be a list of feature to plot\n",
        "    # compare_name = show name of dataframe compare plot legend\n",
        "    \n",
        "    from scipy.stats import norm\n",
        "    \n",
        "    for i, feature in zip(range(len(compare_label)), compare_label) :\n",
        "        fig,ax=plt.subplots(figsize=(11.7,8.27)) # figsize = in inch\n",
        "        sns.distplot(df_1[feature], ax=ax, color='r',kde=True)\n",
        "        sns.distplot(df_2[feature], ax=ax, color='b', kde=True)\n",
        "        plt.title(feature+\" - Distribution Count Plot\")\n",
        "        plt.legend(title='Distribution', loc='upper left', labels=[compare_name[0],compare_name[1]])\n",
        "        \n",
        "        fig,ax1=plt.subplots(figsize=(11.7,8.27))\n",
        "        sns.distplot(df_1[feature], ax=ax1,color='r', kde=True)\n",
        "        sns.distplot(df_2[feature], ax=ax1,color='b', kde=True)\n",
        "        ax1.set_ylim([0,0.5])\n",
        "        plt.title(feature+\" - Distribution Density Plot\")\n",
        "        plt.legend(title='Distribution', loc='upper left', labels=[compare_name[0],compare_name[1]])\n",
        "        \n",
        "        plt.show()\n",
        "\n",
        "        \n",
        "        \n",
        "    return"
      ],
      "id": "c96c04af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2916290"
      },
      "source": [
        "def z_score_outlier_detection_numeric(df,label,gt_value,numeric_feature_column,outlier_threshold_rate,,feature_remove_decision=False,save_plot=False):\n",
        "    ### 1. Calcualte z-score of whole df\n",
        "    ### 2. Detect consider outlier if [- 3sigma >= Z-score >= +3 sigma  == consider outlier ]\n",
        "    ### 3. Remove outlier column from df if:\n",
        "            # [ outlier rate > outlier_threshold_rate ]\n",
        "            # feature_remove_decision = True\n",
        "    ### 4. Plot Z-score Box plot for each feature column\n",
        "    ### 5. Plot output features distribution graph \n",
        "    \n",
        "    \n",
        "    ### Hyper Parameter\n",
        "    # 1. outlier_density_threshold, % = acceptable z-score density threshold before remove\n",
        "    # 2. label is used to plot \n",
        "    # 3. gt_value= Label Ground Truth value\n",
        "    # 3. Z_score_outlier_threshold = z_score removal threhold\n",
        "    # 4. numeric_feature_column = feature to calculate z-score analysis (user need to exclude categorical number column out of the list)\n",
        "    # 5. outlier_removal_rate = column removal % if outlier rate exceed threshold\n",
        "    # 6. save_photo = True = Auto saved photo\n",
        "    \n",
        "    # return ploted z-score box plot\n",
        "    # return outlier cleaned dataframe ( clean column outlier of exceed outlier rate threshold)\n",
        "    \n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns \n",
        "    from scipy import stats\n",
        "    \n",
        "    ## Dataframe Describe Info ##\n",
        "    print(label+' - Data Attribute\\n',df[label].describe())\n",
        "    \n",
        "    \n",
        "    ### Plot Distrubution Label Data Analysis Graph ###\n",
        "    stdev=round(df[label].std(),2) # label stdev\n",
        "    mean=round(df[label].mean(),2) # label mean value \n",
        "    min_value=round(min(df[label]),2) # min label value \n",
        "    max_value=round(max(df[label]),2) # max label value\n",
        "\n",
        "    \n",
        "    UCL= mean+3*stdev # label negative 3-sigma\n",
        "    LCL = mean-3*stdev # label positive 3-sigma\n",
        "    \n",
        "    no_outof_gt_value_spec=len(df[df[label]<gt_value]) # numbers of label value smaller than groundtruth value\n",
        "    no_within_gt_value_spec=len(df)-len(df[df[label]<gt_value]) # numbers of label value within ground truth value\n",
        "    \n",
        "    no_within_3sigma_spec=len(df)-len(df[(df[label]<LCL) | ( df[label]>UCL)]) # numbers of label value within UCL & LCL\n",
        "    \n",
        "    ## Plot Label data Histogram ##\n",
        "    sns.set(rc={'figure.figsize':(20,15)})\n",
        "    plt.figure(100)\n",
        "    sns.distplot(df[label],kde=True)\n",
        "\n",
        "    plt.axvline(gt_value,linestyle='--',color='red') # Numeric label Ground Truth line\n",
        "    plt.axvline(UCL,linestyle='--',color='blue')  # positive 3-sigma\n",
        "    plt.axvline(LCL,linestyle='--',color='green')  # negative 3-sigma\n",
        "    \n",
        "    plt.title(label+ 'Distribution Plot [Within '+label+' Spec:'+str(no_within_gt_value_spec)+', OutofSpec:'+str(no_outof_gt_value_spec)+'] [ Within UCL/LCL:'+str(no_within_3sigma_spec)+'/'+str(len(df))+' ]',fontsize=12)\n",
        "    plt.legend(['Dataset N:'+str(len(df))+' Mean:'+str(mean)+' Max:'+str(max_value)+' Min:'+str(min_value),\n",
        "                label+' Ground Truth',\n",
        "                'UCL',\n",
        "                'LCL'],\n",
        "               fancybox=True,\n",
        "               framealpha=1,\n",
        "               shadow=True,\n",
        "               borderpad=1,fontsize=12)\n",
        "    \n",
        "    plt.xlabel(str(label)+' value',fontsize=12)\n",
        "    plt.ylabel('Counts',fontsize=12)\n",
        "    \n",
        "    if save_plot==True:\n",
        "        plt.savefig(\"Label_Distribution_plot.png\")     # auto Saved figure file\n",
        "\n",
        "    \n",
        "    ############################################################################################################################################################\n",
        "    \n",
        "    \n",
        "    \n",
        "    ## Calcualte Z-score dataframe ##\n",
        "    df_feature_column=df.columns\n",
        "    \n",
        "    new_numeric_feature_column=list() # create a new list to store exist numeric feature column after data cleaning\n",
        "    \n",
        "    for i in df_feature_column:\n",
        "        if i in(numeric_feature_column):\n",
        "            new_numeric_feature_column.append(i)\n",
        "        \n",
        "    df_z_score=df[new_numeric_feature_column] # form new dataframe of new_numeric_feature_column\n",
        "    \n",
        "    \n",
        "    for feature in df_z_score:\n",
        "        stdev=df_z_score[feature].std()\n",
        "        mean=df_z_score[feature].mean()\n",
        "        df_z_score[feature]=(df_z_score[feature]-mean)/stdev\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def outlier_removal(df,df_z_score,outlier_threshold_rate,feature_remove_decision,save_plot):\n",
        "        #  - 3sigma >= Z-score >= +3 sigma  == consider outlier\n",
        "        \n",
        "        outlier_rate_dict={}\n",
        "        total_outlier =0\n",
        "        \n",
        "        for column in df_z_score:\n",
        "            outlier_number =len(df_z_score[df_z_score[column]>3.0]) + len(df_z_score[df_z_score[column]<-3.0])\n",
        "            outlier_rate=outlier_number/len(df_z_score[column])*100    # outlier rate in %\n",
        "            outlier_rate_dict[column]=outlier_rate\n",
        "            \n",
        "            total_outlier=total_outlier + outlier_number\n",
        "        \n",
        "        overall_outlier_rate=total_outlier/ (len(df_z_score)*len(df_z_score.columns))*100 # overall outlier rate of whole dataframe in %\n",
        "        \n",
        "        outlier_remove_column=[]\n",
        "        for key in outlier_rate_dict:\n",
        "            if outlier_rate_dict[key] > outlier_threshold_rate:\n",
        "                outlier_remove_column.append(key)\n",
        "        \n",
        "        outlier_df=pd.DataFrame(outlier_rate_dict.items(),columns=[\"Features\",\"Outlier_rate\"])\n",
        "        outlier_df.sort_values(by=[\"Outlier_rate\"], ascending=True, inplace=True)  \n",
        "        \n",
        "        if feature_remove_decision = True : # if feature_remove_decision is True it will remove the outlier column from df\n",
        "            df.drop(outlier_remove_column,axis=1,inplace=True) # Remove train data outlier column\n",
        "            print('Outlier Remove Decision \"Enable\" ')\n",
        "        else:\n",
        "            print('Outlier Remove Decision \"Disable\" ')\n",
        "            \n",
        "        print(\"outlier_remove_column[>\"+str(outlier_threshold_rate)+\"] : \",outlier_remove_column) # show outlier removed column\n",
        "        \n",
        "        plt.figure()\n",
        "        ax1=sns.lineplot(data=outlier_df, x=\"Features\", y=\"Outlier_rate\", marker='o', sort=True)\n",
        "        ax1.tick_params(axis='x',rotation=90)  # rotate label x by 90 degree\n",
        "        plt.xlabel('Features')\n",
        "        plt.ylabel(\"Outlier Percentage %\")\n",
        "        plt.title(\"Outlier Rate Plot -- Data Shape:\"+str(df_z_score.shape)+\"   Overall Outlier Rate[%]:\"+str(overall_outlier_rate)+\"   Feature Reduction:\"+str(len(outlier_remove_column))+\"(<\"+str(outlier_threshold_rate)+\"%)\")\n",
        "        \n",
        "        if save_plot==True:\n",
        "            plt.savefig(\"Outlier_Rate_plot.png\")      \n",
        "        return df\n",
        "        \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    def z_score_boxplot(df,save_plot):\n",
        "        # input \n",
        "        ### Each graph boxplot contains only 20 features\n",
        "\n",
        "        start_index=0 # plot_column_index start index value \n",
        "        final_index=len(df.columns)\n",
        "\n",
        "        plot_column_list=[]\n",
        "        plot_column_index=[]\n",
        "\n",
        "        max_limit_value=max(df.max())\n",
        "        min_limit_value=min(df.min())\n",
        "\n",
        "        ### Form index list of column to seperate different graph per box plot ###\n",
        "        for i in range(0,len(list(df.columns)),20): # seperate 20 features per graph of box plot\n",
        "            plot_column_index.append(i)\n",
        "        plot_column_index.remove(0)\n",
        "\n",
        "        ### Form Column list of each graph of box plot ###\n",
        "        for i in plot_column_index :\n",
        "            plot_column_list.append(list(df.columns[start_index:i]))\n",
        "            start_index=i\n",
        "\n",
        "        if start_index<final_index:\n",
        "            plot_column_list.append(list(df.columns[start_index:final_index]))\n",
        "            \n",
        "        pic_no=1\n",
        "        ### Plot box plot ###\n",
        "        for column in plot_column_list:\n",
        "\n",
        "            sns.set(rc={'figure.figsize':(20,15)})\n",
        "            plt.figure()\n",
        "            sns.boxplot(data=df[column],orient=\"h\",fliersize=6)\n",
        "            plt.xlim(min_limit_value-2,max_limit_value+2)\n",
        "            plt.xlabel('Z-Score')\n",
        "            plt.ylabel(\"Features\")\n",
        "            plt.title(\"Z-score vs Features BoxPlot\")\n",
        "            \n",
        "            ### Save Plot ###\n",
        "            if save_plot==True:\n",
        "                plt.savefig(\"Boxplot_\"+str(pic_no)+\".png\")     # auto Saved figure file\n",
        "                pic_no+=1 \n",
        "        return\n",
        "    \n",
        "\n",
        "    z_score_boxplot(df_z_score,save_plot) # Call z_score_boxplot function \n",
        "    df = outlier_removal(df,df_z_score,outlier_threshold_rate,feature_remove_decision,save_plot)\n",
        "    \n",
        "    return "
      ],
      "id": "e2916290",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9a0a29"
      },
      "source": [
        "\n",
        "def correlation_filter_function(dataset,corr_dataset,label,corr_method,corr_threshold,remove_feature_decision=False,save_figure=False):\n",
        "    ''' Function will Calculate Correlation Coefficient \n",
        "        Plot Correlation Coeffiecent as Heat map\n",
        "        Show Total Rejected Features ( > corr_threshold )\n",
        "        Show High correlated features pair and corr value ( > corr_threshold )\n",
        "        Plot Top 20 Features to Features Correlation Coeficent Heatmap --> label column\n",
        "        Plot Top 20 Features vs Label Features\n",
        "        return : Dataframe ( remove or not highly correlated feature )\n",
        "    '''\n",
        "    \n",
        "    \"\"\" Function Variables \"\"\"\n",
        "    # dataset = original dataframe \n",
        "    # corr_dataset: Consist of numeric feature from dataframe only\n",
        "    # label = Label Feature column\n",
        "    # corr_method : \"pearson\", \"kendall\", \"spearman\"\n",
        "    # corr_threshold : threshold to reject \"corr value > corr_threshold\"\n",
        "    # remove_feature_decision : True/ False decide to remove or not highly correlated feature from dataframe\n",
        "\n",
        "    \n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    \n",
        "    \n",
        "    def _get_diagonal_pairs(corr_dataset):\n",
        "        \n",
        "        ''' Get diagonal and lower triangular pairs of correlation matrix '''\n",
        "        \n",
        "        pairs_to_drop=set()\n",
        "        cols=corr_dataset.columns\n",
        "\n",
        "        for i in range(len(corr_dataset.columns)):\n",
        "            for j in range(0,i+1):\n",
        "                pairs_to_drop.add((cols[i],cols[j])) # diagonal label col name [ it store index type of pandas series ]\n",
        "\n",
        "        return pairs_to_drop\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    def _get_reject_corr_features(corr_dataset,label,corr_method,corr_threshold,top_features_no):\n",
        "        \n",
        "        ''' Calculate/Show Features to Features Correlation Coefficient Value '''\n",
        "        \n",
        "        corr_df = corr_dataset.corr(method=corr_method).unstack() # corr value non-absolute\n",
        "        \n",
        "        corr_abs_df = corr_dataset.corr(method=corr_method).abs().unstack() # absolute corr Series, from \"Dataframe\" unstack to a list of \"Pandas Series\"\n",
        "        labels_to_drop = _get_diagonal_pairs(corr_dataset) \n",
        "        \n",
        "        corr_abs_df = corr_abs_df.drop(labels=labels_to_drop).sort_values(ascending=False) # drop repeated pairs corr value and sort by descending order\n",
        "        corr_idx = corr_abs_df.index # get pandas series index of descending order\n",
        "        corr_df=corr_df.reindex(index=corr_idx) # re-arrange without absolute corr value to descending order\n",
        "        \n",
        "        print(f'All Correlation Features Pairs (Corr Features Pair Values>{str(corr_threshold)}) :\\n\\n {corr_df[ corr_df > corr_threshold]}')\n",
        "\n",
        "        #         corr_df = corr_df.drop(labels=labels_to_drop) # Drop \"pandas series\" by (column_name_1, column_name_2)\n",
        "        #         # argsort returns only index of ascending order [::-1] re-arrange index inversly = sort in descending order\n",
        "        #         sort_corr_abs_idx = corr_abs_df.argsort().[::-1] # return descending sort order index  = Highest Correlation cooeficient index\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \"\"\" Plot Top Features vs Label Features \"\"\"\n",
        "        \n",
        "        top_highest_corr_features_index=list(corr_dataset.corr()[label].abs().sort_values(ascending=False)[1:top_features_no+1].index) # Sort Corr abs value as descending order and set as list of index\n",
        "\n",
        "        plt.figure()\n",
        "        # Heatmap require input 2D\n",
        "        # plot single column dataframe into heatmap need to df[['columns']] will result in 2D suitable for heatmap input\n",
        "        sns.heatmap(corr_dataset.corr()[[label]].loc[top_highest_corr_features_index],annot=True, fmt=\".2f\", cmap='Blues')\n",
        "        plt.title(f' Top {top_features_no} Features vs {label} {corr_method} Corrleation ')\n",
        "        \n",
        "        # Save Figure\n",
        "        if save_figure == True:\n",
        "            plt.savefig(f'Top_{top_features_no}_Features_vs_{label}_{corr_method}_Corrleation.png')\n",
        "              \n",
        "        \n",
        "        \n",
        "        \n",
        "        \"\"\" Plot Top Features to Features Correlation Coeficent Heatmap --> label column \"\"\"\n",
        "                \n",
        "        corr_matrix=corr_dataset[top_highest_corr_features_index].corr()\n",
        "        plt.figure(figsize=(15,15))\n",
        "        # \"annot\" = True = show readings\n",
        "        # \"fmt\" = use to set decimal .2f = 2 float decimal\n",
        "        sns.heatmap(corr_matrix,annot=True, fmt=\".2f\", cmap='Blues') \n",
        "        plt.title(f' Top {top_features_no} {label} - Features to Features {corr_method} Corrleation ')\n",
        "        \n",
        "        # Save Figure\n",
        "        if save_figure == True:\n",
        "            plt.savefig(f'Top_{top_features_no}_{label}_Features_to_Features_{corr_method}_Corrleation.png')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \"\"\" Correlation Plot and return high correlated features as \"col_corr\" \"\"\"\n",
        "    \n",
        "        reject_col_corr=set() # set is use because it does not add duplicate same value in a set() variables\n",
        "        corr_matrix= corr_dataset.corr(method=corr_method)\n",
        "        \n",
        "        # Plot figure\n",
        "        plt.figure(figsize=(12,10))\n",
        "        sns.heatmap(corr_matrix,annot=True)\n",
        "        plt.title(f'{corr_method} Correlation Coeficient All Features [Feature Size={corr_matrix.shape}]')\n",
        "        \n",
        "        # Save Figure\n",
        "        if save_figure == True:\n",
        "            plt.savefig('Correlation_Coefficient_All_Features.png')\n",
        "        \n",
        "        # Extract Out of corr_threshold features\n",
        "        col=corr_matrix.columns \n",
        "        \n",
        "        for i in range(len(corr_matrix.columns)):\n",
        "            for j in range(i):\n",
        "                if (corr_matrix.iloc[i,j])>corr_threshold:\n",
        "                    \n",
        "                    # add remove features to set for correlation value of features vs label is the smallest\n",
        "                    if corr_matrix.loc[col[i],label]< corr_matrix.loc[col[j],label]: \n",
        "                        reject_col_corr.add(col[i])\n",
        "                    else:\n",
        "                        reject_col_corr.add(col[j]) \n",
        "                        \n",
        "        print(f'\\nSize of Rejected Corr features :{len(reject_col_corr)} (>{str(corr_threshold)}) ')\n",
        "        \n",
        "        print(f'\\n Rejected Corr Features : \\n\\n {reject_col_corr}')\n",
        "        \n",
        "        return reject_col_corr\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \"\"\" Show Correlation Values of Pair Features \" \"\"\"\n",
        "    # Run Correlation Coefficient analaysis\n",
        "    reject_col_corr = _get_reject_corr_features(corr_dataset,label,corr_method,corr_threshold,20)\n",
        "    \n",
        "    # Remove out of corr_threshold features\n",
        "    if remove_feature_decision == True:\n",
        "        dataset = dataset.drop(reject_col_corr, axis=1)\n",
        "    \n",
        "    \n",
        "    return dataset\n",
        "    "
      ],
      "id": "bf9a0a29",
      "execution_count": null,
      "outputs": []
    }
  ]
}